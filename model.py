# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mkld9I9by5bKCh5Kql1uPU39JlPxiilO

This is a clean, professional Flax implementation
"""

import jax
import jax.numpy as jnp
import flax.linen as nn

class PositionalEncoding(nn.Module):
    d_model: int
    max_len: int = 5000

    @nn.compact
    def __call__(self, x):
        pos_emb = self.param(
            "pos_embedding",
            nn.initializers.normal(stddev=0.02),
            (self.max_len, self.d_model),
        )
        return x + pos_emb[:x.shape[1], :]


class TransformerBlock(nn.Module):
    d_model: int
    num_heads: int
    mlp_dim: int
    dropout: float = 0.1

    @nn.compact
    def __call__(self, x, train=True):
        # Self attention
        attn = nn.SelfAttention(
            num_heads=self.num_heads,
            qkv_features=self.d_model,
            dropout_rate=self.dropout,
        )
        x2 = attn(x)
        x = x + x2
        x = nn.LayerNorm()(x)

        # Feedforward
        ff = nn.Sequential([
            nn.Dense(self.mlp_dim),
            nn.gelu,
            nn.Dense(self.d_model),
        ])
        x2 = ff(x)
        x = x + x2
        x = nn.LayerNorm()(x)
        return x


class TimeSeriesTransformer(nn.Module):
    d_model: int = 128
    num_heads: int = 4
    num_layers: int = 4
    mlp_dim: int = 256
    dropout: float = 0.1
    seq_len: int = 60

    @nn.compact
    def __call__(self, x, train=True):
        # Expect input shape (batch, seq_len)
        x = x[..., None]                     # add feature dim â†’ (B, L, 1)
        x = nn.Dense(self.d_model)(x)        # project to model dim

        x = PositionalEncoding(self.d_model)(x)

        for _ in range(self.num_layers):
            x = TransformerBlock(
                self.d_model,
                self.num_heads,
                self.mlp_dim,
                self.dropout,
            )(x, train=train)

        # Predict next value from final token
        last = x[:, -1, :]
        out = nn.Dense(1)(last)
        return out.squeeze(-1)

